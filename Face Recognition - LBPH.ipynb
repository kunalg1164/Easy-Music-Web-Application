{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.6.0.66-cp36-abi3-win_amd64.whl (42.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\z004a1wv\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.21.6)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.6.0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\z004a1wv\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "* Prepare training data\n",
    "* Face detection\n",
    "* Training\n",
    "* Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating database \n",
    "database = [\"Tom Cruise\", \"Gaurav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    face = haar_classifier.detectMultiScale(image_gray)\n",
    "    (x,y,w,h) = face[0]\n",
    "    return image_gray[y:y+w, x:x+h], face[0]\n",
    "def prepare_data(data_path):\n",
    "    folders = os.listdir(data_path)\n",
    "    labels = []\n",
    "    faces = []\n",
    "    for folder in folders:\n",
    "        label = int(folder)\n",
    "        training_images_path = data_path + '/' + folder\n",
    "        print(training_images_path)\n",
    "        for image in os.listdir(training_images_path):\n",
    "            image_path = training_images_path + '/' + image\n",
    "            print(image_path)\n",
    "            training_image = cv2.imread(image_path)\n",
    "            try: \n",
    "                face, bounding_box = face_detection(training_image)\n",
    "                faces.append(face)\n",
    "                labels.append(label)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    print ('Training Done')\n",
    "    return faces, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/10\n",
      "dataset/10/1.jpg\n",
      "dataset/10/10.jpg\n",
      "dataset/10/11.jpg\n",
      "dataset/10/12.jpg\n",
      "dataset/10/13.jpg\n",
      "dataset/10/14.jpg\n",
      "dataset/10/15.jpg\n",
      "dataset/10/16.jpg\n",
      "dataset/10/17.jpg\n",
      "dataset/10/18.jpg\n",
      "dataset/10/19.jpg\n",
      "dataset/10/2.jpg\n",
      "dataset/10/20.jpg\n",
      "dataset/10/21.jpg\n",
      "dataset/10/22.jpg\n",
      "dataset/10/23.jpg\n",
      "dataset/10/24.jpg\n",
      "dataset/10/25.jpg\n",
      "dataset/10/26.jpg\n",
      "dataset/10/27.jpg\n",
      "dataset/10/28.jpg\n",
      "dataset/10/29.jpg\n",
      "dataset/10/3.jpg\n",
      "dataset/10/30.jpg\n",
      "dataset/10/31.jpg\n",
      "dataset/10/32.jpg\n",
      "dataset/10/33.jpg\n",
      "dataset/10/34.jpg\n",
      "dataset/10/35.jpg\n",
      "dataset/10/36.jpg\n",
      "dataset/10/4.jpg\n",
      "dataset/10/5.jpg\n",
      "dataset/10/6.jpg\n",
      "dataset/10/7.jpg\n",
      "dataset/10/8.jpg\n",
      "dataset/10/9.jpg\n",
      "Training Done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total faces =  31\n",
      "Total labels =  31\n"
     ]
    }
   ],
   "source": [
    "print ('Total faces = ', len(faces))\n",
    "print ('Total labels = ', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBPH Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces, labels = prepare_data('dataset')\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(test_image):\n",
    "    img = test_image.copy()\n",
    "    face, bounding_box = face_detection(img)\n",
    "    label = model.predict(face)\n",
    "    print(label)\n",
    "    label_text = str(label[0])\n",
    "    print (label)\n",
    "    print (label_text)\n",
    "    (x,y,w,h) = bounding_box\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "    cv2.putText(img, label_text, (x,y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database=[0,0,0,0,0,0,0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 0.0)\n",
      "(10, 0.0)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "test1 = cv2.imread(\"dataset/10/1.jpg\")\n",
    "# print(test1)\n",
    "predict1 = predict_image(test1)\n",
    "cv2.imshow('Face Recognition', predict1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
